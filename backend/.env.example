# Azure OpenAI Configuration (via APIM)
AZURE_OPENAI_API_KEY="your-apim-subscription-key"
AZURE_OPENAI_ENDPOINT="https://psacodesprint2025.azure-api.net/"
AZURE_EMBED_DEPLOYMENT="text-embedding-3-small"
AZURE_CHAT_DEPLOYMENT="gpt-5-mini"

# Embedding Model Selection
# Set to 'true' to use local sentence-transformers first (fast, free, offline)
# Set to 'false' or omit to use Azure OpenAI embeddings first (higher quality, requires API)
USE_LOCAL_EMBEDDINGS=false

# Flask Configuration
FLASK_ENV=development
DATABASE_URL=sqlite:///compass.db

# ============================================================================
# CACHE CONFIGURATION
# ============================================================================

# Cache Backend Selection
# Set to 'true' to use Redis (recommended for production)
# Set to 'false' to use in-memory LRU cache (good for development)
USE_REDIS_CACHE=false

# Redis Configuration (only used if USE_REDIS_CACHE=true)
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
REDIS_PASSWORD=

# In-Memory Cache Configuration
# Maximum number of items to cache when using in-memory backend
MEMORY_CACHE_MAX_SIZE=1000

# Cache TTL (Time To Live) in seconds
# Embeddings cache - Text embeddings rarely change
CACHE_TTL_EMBEDDING=86400

# Role matching cache - Balance freshness and performance
CACHE_TTL_ROLE_MATCH=3600

# Leadership scoring cache - Scores are relatively stable
CACHE_TTL_LEADERSHIP=7200

# Career roadmap cache - Roadmaps need reasonable freshness
CACHE_TTL_ROADMAP=3600

# AI narrative cache - Generated text can be cached briefly
CACHE_TTL_NARRATIVE=1800

# AI copilot responses - Short cache for conversational AI
CACHE_TTL_AI_RESPONSE=900

# Cache Features
# Enable automatic cache warming (pre-compute expensive operations)
ENABLE_CACHE_WARMING=false

# Enable cache statistics tracking
ENABLE_CACHE_STATS=true

